{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Description.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RWuQ7eyGyU-S","colab_type":"text"},"source":["#**Đồ án Môn học**"]},{"cell_type":"markdown","metadata":{"id":"IrIAceMRypnf","colab_type":"text"},"source":["##**Đề tài: Dự đoán loại trái cây trong ảnh**"]},{"cell_type":"markdown","metadata":{"id":"WKqDGkTgzuW0","colab_type":"text"},"source":["#**1. Mô tả bài toán:**\n","+ Phát biểu bài toán: Phân loại trái cây có trong một bức ảnh\n","+ Input: một bức ảnh\n","+ Output: tên của một loại trái trong ảnh  "]},{"cell_type":"markdown","metadata":{"id":"xrFg69AZ1stF","colab_type":"text"},"source":["#**2. Mô tả về bộ dữ liệu:**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"384QkTGo2Ba2","colab_type":"text"},"source":["+ Dataset thu thập cùng với các bạn Thịnh, Xuân Trí bằng cách đi chụp ảnh,quay video các loại trái cây trong siêu thị.\n","+ Bộ dữ liệu train (được chứa trong folder Train_data) gồm 11020 bức ảnh .png tách frame từ các video được quay bằng điện thoại + 2700 ảnh .png được chụp bằng điện thoại. Các bức ảnh sau quá trình tiền xử lí dữ liệu bằng tay (lọc các ảnh mờ, ảnh có độ nhiễu cao, cắt giảm background từng tấm hình) được chia vào 12 class là : class Apple (Táo), class Avocado (Bơ), class Banana (Chuối), class Coconut (Dừa), class Custard_apple (Mãng cầu), class Dragon_fruit (Thanh Long), class Guava (Ổi), claas Mango (Xoài), class Orange (Cam), class Plum (Mận), class Start_fruit (Khế), class Watermelon (Dưa hấu) :\n","        class Apple          : 1159 ảnh \n","        class Avocado        : 1478 ảnh\n","        class Banana         : 1308 ảnh\n","        class Coconut        : 1185 ảnh\n","        class Custard_apple  : 941  ảnh \n","        class Dragon_fruit   : 682  ảnh\n","        class Guava          : 989  ảnh \n","        class Mango          : 966  ảnh\n","        class Orange         : 1488 ảnh\n","        class Plum           : 1482 ảnh \n","        class Start_fruit    : 1175 ảnh \n","        class Watermelon     : 957  ảnh \n","+ Bộ dữ liệu test gồm 2400 ảnh .png được chụp bằng điện thoại, được chia thành 12 class trái cây giống như tập train, mỗi loại gồm 200 bức ảnh (Được chứa trong folder Test_data)"]},{"cell_type":"markdown","metadata":{"id":"l16LGzHH-4f5","colab_type":"text"},"source":["- Bộ dữ liệu test thứ 2 gồm 120 ảnh được down trực tiếp bằng tay từ trên google, chia đều vào 12 class trái cây, mỗi loại gồm 10 bức ảnh (Được chứa trong folder predict)"]},{"cell_type":"markdown","metadata":{"id":"FYq03EXK8934","colab_type":"text"},"source":["#**3. Mô tả vector đặc trưng:**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"smfwQJC2mu6H","colab_type":"text"},"source":["**Đề xuất: Thử với 3 kiểu rút trích đặc trưng**\n"]},{"cell_type":"markdown","metadata":{"id":"cvPqlyhunFva","colab_type":"text"},"source":["- **Cách đơn giản nhất:** Sau khi resize tất cả ảnh về cùng một kích thước (32* \n","32 *3). Coi mỗi pixel trong 1 bức ảnh là 1 feature.  Resize bức ảnh về vector \n","có kích thước (3072,1)\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qHqZPwyvnxov","colab_type":"text"},"source":["- **Local Binary Patterns:** Local binary pattern nó là một thuật toán mô tả texture(cầu trúc) của một image. Ý tưởng cơ bản của nó là mô phỏng lại cấu trúc cục bộ (local texture) của image bằng cách so sánh mỗi pixel với các pixel lân cận nó(neighbors).Ta sẽ đặt một pixel là trung tâm(center) và so sánh với các pixel lân cận với nó, nếu pixel trung tâm lớn hơn hoặc bằng pixel lân cận thì nó sẽ trả về giá trị 1, ngược lại 0. "]},{"cell_type":"markdown","metadata":{"id":"S0rcEXgGpkY7","colab_type":"text"},"source":["         + Ví dụ: chúng ta lấy bán kính 8 pixel lân cận thì lbp sẽ có dạng 11001111, là một chuỗi nhị phân để đơn giản \n","         và dễ đọc hơn ta sẽ chuyển về dạng decimal 207."]},{"cell_type":"markdown","metadata":{"id":"ziSv8gnJYo2E","colab_type":"text"},"source":["<img src='https://drive.google.com/uc?id=14LQKhW_risYx-1_7UMyhvI3m3gGGHhlA' width=500/>"]},{"cell_type":"markdown","metadata":{"id":"sWWEWpb6rJdY","colab_type":"text"},"source":["      + Cách tính này có hạn chế đó là chỉ giới hạn 3x3 pixel không đủ để mô tả các cấu trúc large scale nên người ta mở rộng khái niệm \n","      LBP bằng cách định nghĩa thêm 2 tham số là (P,R) trong đó P là số pixel lân cận xem xét và R là bán kính ta quét từ pixel trung \n","      tâm. Như hình bên dưới. "]},{"cell_type":"markdown","metadata":{"id":"1tOEb7c1ruVX","colab_type":"text"},"source":["<img src='https://drive.google.com/uc?id=1fxcKwkNm2NaN9txG2A602ETnAEjexHoD' width=500/>"]},{"cell_type":"markdown","metadata":{"id":"rG91aSTGurDQ","colab_type":"text"},"source":["**Tham khảo:** https://thorpham.github.io/blog/2018/02/22/feature-exaction/"]},{"cell_type":"markdown","metadata":{"id":"0Za_lzrSr8av","colab_type":"text"},"source":["- **Histogram Oriented of Gradient :**\n","        +  HOG là viết tắt của Histogram of Oriented Gradient - một loại “feature descriptor”. Mục đích của “feature \n","        descriptor” là trừu tượng hóa đối tượng bằng cách trích xuất ra những đặc trưng của đối tượng đó và bỏ đi \n","        những thông tin không hữu ích. Vì vậy, HOG được sử dụng chủ yếu để mô tả hình dạng và sự xuất hiện của một \n","        đối tượng trong ảnh."]},{"cell_type":"markdown","metadata":{"id":"Ls1cOIR3yZfN","colab_type":"text"},"source":["            +  Bản chất của phương pháp HOG là sử dụng thông tin về sự phân bố của các cường độ gradient (intensity gradient) hoặc của\n","             hướng biên (edge directins) để mô tả các đối tượng cục bộ trong ảnh. "]},{"cell_type":"markdown","metadata":{"id":"4gFkpam6vL-P","colab_type":"text"},"source":["**Tham khảo:** https://viblo.asia/p/tim-hieu-ve-phuong-phap-mo-ta-dac-trung-hog-histogram-of-oriented-gradients-V3m5WAwxZO7"]},{"cell_type":"markdown","metadata":{"id":"e3OCz4maB3_G","colab_type":"text"},"source":["#**4. Mô tả các thuật toán máy học:**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JxFDmkBu6HlX","colab_type":"text"},"source":["**Đề xuất:** Thử với 5 model từ thư viện Sklearn và 2 model mạng Convolutional Neural Networks"]},{"cell_type":"markdown","metadata":{"id":"dRDPDkCp6Liz","colab_type":"text"},"source":["> **Năm model từ thư viện sklearn**"]},{"cell_type":"markdown","metadata":{"id":"hqYafjO46TDi","colab_type":"text"},"source":["          - LogisticRegression\n","          - DecisionTreeClassifier\n","          - KNeighborsClassifier\n","          - GaussianNB\n","          - SVM \n"]},{"cell_type":"markdown","metadata":{"id":"3aTZJO5V5tEI","colab_type":"text"},"source":[">**Hai mạng Convolutional Neural Networks**"]},{"cell_type":"markdown","metadata":{"id":"bVXPaL1E5CF3","colab_type":"text"},"source":["- Shallownet: Mạng neural 2 lớp\n","        + Cấu trúc mạng như sau :\n","              INPUT => CONV => RELU => FC\n"]},{"cell_type":"markdown","metadata":{"id":"7MTE-zHP2Kdy","colab_type":"text"},"source":["- Lenet: Em thực hiện dựa trên ý tưởng từ mạng Lenet gốc, được đề xuất bởi Yann LeCun trong một bài báo năm 1998 \n","      + Cấu trúc của mạng Lenet như sau:\n","              "]},{"cell_type":"markdown","metadata":{"id":"EfeO_EySiwLc","colab_type":"text"},"source":["<img src='https://drive.google.com/uc?id=1FPrui_jIVmfs47Tg7uaaz5i1rnMRoAdT' width=500/>"]},{"cell_type":"markdown","metadata":{"id":"bdpSwmxC0hVK","colab_type":"text"},"source":["        \n","        + Nguồn tham khảo: * http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\n","                           * Sách Deep Learning for Cumputer Vision (Adrian RoseBrock)"]},{"cell_type":"markdown","metadata":{"id":"12zkc42XOsiS","colab_type":"text"},"source":["## **Các phương pháp đánh giá một hệ thống phân lớp**"]},{"cell_type":"markdown","metadata":{"id":"Q57aPtZ0PDEf","colab_type":"text"},"source":["###**a. Accuracy**"]},{"cell_type":"markdown","metadata":{"id":"Uvp03n0pPcUP","colab_type":"text"},"source":["- Cách đơn giản và hay được sử dụng nhất là accuracy (độ chính xác). Cách đánh giá này đơn giản tính tỉ lệ giữa số điểm được dự đoán đúng và tổng số điểm trong tập dữ liệu kiểm thử.\n","      + Ví dụ:  Ta có thể đếm được có 6 điểm dữ liệu được dự đoán đúng trên tổng số 10 điểm. Vậy ta kết luận độ \n","      chính xác của mô hình là 0.6 (hay 60%)."]},{"cell_type":"markdown","metadata":{"id":"LSrTBK_pP7DK","colab_type":"text"},"source":["###**b. Confusion matrix**"]},{"cell_type":"markdown","metadata":{"id":"IlgxTpIFQEkC","colab_type":"text"},"source":["- Tuy nhiên cách tính sử dụng accuracy như ở trên chỉ cho chúng ta biết được bao nhiêu phần trăm lượng dữ liệu được phân loại đúng mà không chỉ ra được cụ thể mỗi loại được phân loại như thế nào, lớp nào được phân loại đúng nhiều nhất, và dữ liệu thuộc lớp nào thường bị phân loại nhầm vào lớp khác. Để có thể đánh giá được các giá trị này, chúng ta sử dụng một ma trận được gọi là confusion matrix."]},{"cell_type":"markdown","metadata":{"id":"ndJIMpxYQU1P","colab_type":"text"},"source":["- Về cơ bản, confusion matrix thể hiện có bao nhiêu điểm dữ liệu thực sự thuộc vào một class, và được dự đoán là rơi vào một class. "]},{"cell_type":"markdown","metadata":{"id":"r912HpvkRlzX","colab_type":"text"},"source":["          + Ví dụ: Tập dữ liệu kiểm thử tổng cộng  10 điểm dữ liệu với 3 lớp dữ liệu. Chúng ta xét ma trận tạo bởi các giá trị tại \n","          vùng 3x3 trung tâm của bảng."]},{"cell_type":"markdown","metadata":{"id":"S1jHYXTAQ-cb","colab_type":"text"},"source":["<img src='https://drive.google.com/uc?id=183pjA3_Hok9Am2uoYuZWGSgOBbrsTHDk' width=500/>"]},{"cell_type":"markdown","metadata":{"id":"QUGkduKQRave","colab_type":"text"},"source":["\n","\n","- Ma trận thu được được gọi là confusion matrix. Nó là một ma trận vuông với kích thước mỗi chiều bằng số lượng lớp dữ liệu. Giá trị tại hàng thứ i, cột thứ j là số lượng điểm lẽ ra thuộc vào class i nhưng lại được dự đoán là thuộc vào class j. Như vậy, nhìn vào hàng thứ nhất (0), ta có thể thấy được rằng trong số bốn điểm thực sự thuộc lớp 0, chỉ có hai điểm được phân loại đúng, hai điểm còn lại bị phân loại nhầm vào lớp 1 và lớp 2."]},{"cell_type":"markdown","metadata":{"id":"U40qRSjCSnlk","colab_type":"text"},"source":["###**c. True/False Positive/Negative**"]},{"cell_type":"markdown","metadata":{"id":"6jvQ7gjNS0it","colab_type":"text"},"source":["- Cách đánh giá này thường được áp dụng cho các bài toán phân lớp có hai lớp dữ liệu. Cụ thể hơn, trong hai lớp dữ liệu này có một lớp nghiêm trọng hơn lớp kia và cần được dự đoán chính xác. Ví dụ, trong bài toán xác định có bệnh ung thư hay không thì việc không bị sót (miss) quan trọng hơn là việc chẩn đoán nhầm âm tính thành dương tính. Trong bài toán xác định có mìn dưới lòng đất hay không thì việc bỏ sót nghiêm trọng hơn việc báo động nhầm rất nhiều. Hay trong bài toán lọc email rác thì việc cho nhầm email quan trọng vào thùng rác nghiêm trọng hơn việc xác định một email rác là email thường."]},{"cell_type":"markdown","metadata":{"id":"U6YaNooWS56g","colab_type":"text"},"source":["- Trong những bài toán này, người ta thường định nghĩa lớp dữ liệu quan trọng hơn cần được xác định đúng là lớp Positive (P-dương tính), lớp còn lại được gọi là Negative (N-âm tính). Ta định nghĩa True Positive (TP), False Positive (FP), True Negative (TN), False Negative (FN) dựa trên confusion matrix chưa chuẩn hoá như sau:"]},{"cell_type":"markdown","metadata":{"id":"PL5qW1K1TpCg","colab_type":"text"},"source":["<img src='https://drive.google.com/uc?id=1AGYpTg1L9QYxepLgWc2e7dMP_ElvAOui' width=500/>"]},{"cell_type":"markdown","metadata":{"id":"oiJRDSbxUzse","colab_type":"text"},"source":["- Người ta thường quan tâm đến TPR, FNR, FPR, TNR (R - Rate) dựa trên normalized confusion matrix như sau:"]},{"cell_type":"markdown","metadata":{"id":"Lc4psrNgVPuq","colab_type":"text"},"source":["<img src='https://drive.google.com/uc?id=1H-43wNVwS1lt4PMbsLOG1k1P9P2xD0Qe' width=500/>"]},{"cell_type":"markdown","metadata":{"id":"E-LsinIIVe67","colab_type":"text"},"source":["- False Positive Rate còn được gọi là False Alarm Rate (tỉ lệ báo động nhầm), False Negative Rate còn được gọi là Miss Detection Rate (tỉ lệ bỏ sót). Trong bài toán dò mìn, thà báo nhầm còn hơn bỏ sót, tức là ta có thể chấp nhận False Alarm Rate cao để đạt được Miss Detection Rate thấp."]},{"cell_type":"markdown","metadata":{"id":"xRtgfwRjVmnZ","colab_type":"text"},"source":["- **Chú ý:**\n","          + Việc biết một cột của confusion matrix này sẽ suy ra được cột còn lại vì tổng các hàng luôn bằng 1 và chỉ\n","           có hai lớp dữ liệu.\n","\n","          + Với các bài toán có nhiều lớp dữ liệu, ta có thể xây dựng bảng True/False Positive/Negative cho mỗi lớp \n","          nếu coi lớp đó là lớp Positive, các lớp còn lại gộp chung thành lớp Negative"]},{"cell_type":"markdown","metadata":{"id":"FbGbDWWUWnIK","colab_type":"text"},"source":["###**d. Precision và Recall**"]},{"cell_type":"markdown","metadata":{"id":"qtj1qwwHW8OM","colab_type":"text"},"source":["- Với bài toán phân loại mà tập dữ liệu của các lớp là chênh lệch nhau rất nhiều, có một phép đó hiệu quả thường được sử dụng là Precision-Recall.\n","\n","- Trước hết xét bài toán phân loại nhị phân. Ta cũng coi một trong hai lớp là positive, lớp còn lại là negative."]},{"cell_type":"markdown","metadata":{"id":"myVD7_iHXYjK","colab_type":"text"},"source":["<img src='https://drive.google.com/uc?id=19B6fkwDCVMIOZVW0aaliUktGCRXsEmsX' width=500/>"]},{"cell_type":"markdown","metadata":{"id":"h7F7wEVzXvjh","colab_type":"text"},"source":["- Với một cách xác định một lớp là positive, Precision được định nghĩa là tỉ lệ số điểm true positive trong số những điểm được phân loại là positive (TP + FP).\n","\n","- Recall được định nghĩa là tỉ lệ số điểm true positive trong số những điểm thực sự là positive (TP + FN)."]},{"cell_type":"markdown","metadata":{"id":"CrIU5aTjYIZH","colab_type":"text"},"source":["- Khi Recall = 1, mọi điểm positive đều được tìm thấy. Tuy nhiên, đại lượng này lại không đo liệu có bao nhiêu điểm negative bị lẫn trong đó. Nếu mô hình phân loại mọi điểm là positive thì chắc chắn Recall = 1, tuy nhiên dễ nhận ra đây là một mô hình cực tồi.\n","\n","- Một mô hình phân lớp tốt là mô hình có cả Precision và Recall đều cao, tức càng gần một càng tốt. Có cách đo chất lượng của bộ phân lớp dựa vào Precision và Reall: F1-score"]},{"cell_type":"markdown","metadata":{"id":"XdF5PWLPY45j","colab_type":"text"},"source":["<img src='https://drive.google.com/uc?id=1Y88TaKZ-MxPy55IG_hgVOzh6mMqet9Oi' width=500/>"]},{"cell_type":"markdown","metadata":{"id":"X3ZhrH47fE0e","colab_type":"text"},"source":["Nguồn tham khảo: https://machinelearningcoban.com/2017/08/31/evaluation/"]},{"cell_type":"markdown","metadata":{"id":"GuzIBTL4dQm3","colab_type":"text"},"source":["##**Định nghĩa Cross-validation**"]},{"cell_type":"markdown","metadata":{"id":"DgAZk-GvdiSp","colab_type":"text"},"source":["- Cross validation là một cải tiến của validation với lượng dữ liệu trong tập validation là nhỏ nhưng chất lượng mô hình được đánh giá trên nhiều tập validation khác nhau. Một cách thường đường sử dụng là chia tập training ra k tập con không có phần tử chung, có kích thước gần bằng nhau. Tại mỗi lần kiểm thử , được gọi là run, một trong số k tập con được lấy ra làm validata set. Mô hình sẽ được xây dựng dựa vào hợp của k−1 tập con còn lại. Mô hình cuối được xác định dựa trên trung bình của các train error và validation error. Cách làm này còn có tên gọi là k-fold cross validation."]},{"cell_type":"markdown","metadata":{"id":"vyOh6DlddoqH","colab_type":"text"},"source":["Nguồn tham khảo: https://machinelearningcoban.com/2017/03/04/overfitting/"]},{"cell_type":"markdown","metadata":{"id":"jnC-bchU1Vv0","colab_type":"text"},"source":["##**Định nghĩa Stratified Cross Valiadtion:**"]},{"cell_type":"markdown","metadata":{"id":"fzxUDWsZ9OLH","colab_type":"text"},"source":["- Là phiên bản cải tiến của Cross validation, thay vì chia ngẫu nhiên tập dữ liệu train thành k fold (Cross validation), Cross Validation chia tập dữ liệu train thành k fold theo một phân phối xác suất (mean, variance,...)"]},{"cell_type":"markdown","metadata":{"id":"Q4e7LW2h40qT","colab_type":"text"},"source":["<img src='https://drive.google.com/uc?id=1J3dZ4z9bmsCabM_roZQIrIGblQ4tMstQ' width=500/>"]},{"cell_type":"markdown","metadata":{"id":"JdIbH0Bh-gkw","colab_type":"text"},"source":["Nguồn tham khảo: https://stats.stackexchange.com/questions/49540/understanding-stratified-cross-validation?fbclid=IwAR2e1X1Sp-81Hy5E3Ooe9BQ_cb_arElXr0SWp8QxZ_S46T1o-zBd651PjF0"]},{"cell_type":"markdown","metadata":{"id":"8Fly1scOEUsM","colab_type":"text"},"source":["# **5. Cài đặt, tinh chỉnh tham số:**"]},{"cell_type":"markdown","metadata":{"id":"oq3UDhZJ6l0K","colab_type":"text"},"source":["###**a. RandomizedSearchCV**"]},{"cell_type":"markdown","metadata":{"id":"ZQuBzBADcFyE","colab_type":"text"},"source":["+ RandomizedSearchCV là một phương pháp tìm bộ hyperparameters bằng cách từ những giá trị parameter đã setting, Random Search sẽ chọn ngẫu nhiên các cặp parameter sao cho độ chính xác của tập cần dự đoán là lớn nhất theo một độ đo nhất định nào đó (F1-score, Accuracy, ROC,..) \n","\n","    **Ưu điểm** : RandomizedSearchCV thường có thời gian chạy nhanh.\n","\n","    **Nhược điểm**:  Vì random một số bộ parameter nên có khi kết quả khồng được tối ưu, và dẫn đến không được như ý muốn."]},{"cell_type":"markdown","metadata":{"id":"tM-4ZWDeCsaP","colab_type":"text"},"source":["###**b. Cài đặt**  "]},{"cell_type":"markdown","metadata":{"id":"8eolrTL1C1ys","colab_type":"text"},"source":["+ Sử dụng RandomizedSearchCV cùng với StratifiedKFold(n_split=5) để tuning model.\n","+ Đối với K-NN tinh chỉnh bộ tham số:\n","        leaf_size = list(range(1,50))\n","        n_neighbors = list(range(1,30))\n","        p=[1,2]\n","    \n","+ Đối với SVM tinh chỉnh bộ tham số:\n","        C: [0.1, 1],  \n","        gamma: [1, 0.1], \n","        kernel: ['linear', 'poly', 'rbf']"]},{"cell_type":"markdown","metadata":{"id":"uthAU0QkEd7s","colab_type":"text"},"source":["#**6. Đánh giá kết quả, kết luận:**\n"]},{"cell_type":"markdown","metadata":{"id":"k7lwJ2WOAtqY","colab_type":"text"},"source":["Sau nhiều lần thử nghiệm trên 5 loại model sklearn và 2 loại model Convolutional Neural Networks, tinh chỉnh tham số, em thấy:\n","- Đối với model Sklearn: sau khi lấy đại diện 3 model có độ chính xác f1_score cao nhất train trên 3 loại vector đặc trưng khác nhau (SVM cho vector normal, KNN cho vector local binary pattern, SVM cho vector histogram), đánh giá cả 3 model trên bộ dữ liệu test một (gồm 2400 bức ảnh):\n","      + Model SVM dùng với trích xuất vector normal cho độ chính xác f1_score cao nhất (88%) \n","      + Model SVM với trích xuất vector histogram cho độ chính xác f1_score (67%) \n","      + Model KNN cho trích xuất vector local binary pattern với độ chính xác f1_score thấp nhất (35%)  "]},{"cell_type":"markdown","metadata":{"id":"vzK0rpbMDG7g","colab_type":"text"},"source":["- Đối với model Convolutional Neural Networks"]},{"cell_type":"markdown","metadata":{"id":"GR-e6QZfDSoH","colab_type":"text"},"source":["          + Mạng Lenet cho độ chính xác f1_score cao hơn khi sử dụng mạng Shallownet (94% so với 88%)"]},{"cell_type":"markdown","metadata":{"id":"0mV4xCfbZpVj","colab_type":"text"},"source":["###**Kết luận**"]},{"cell_type":"markdown","metadata":{"id":"pOgAoidNZ1T8","colab_type":"text"},"source":["+ Sau khi thử lại với tập Test mới có mỗi bức ảnh có size là 128x128, thì đối với:\n","        Model SVM dùng với trích xuất vector normal cho độ chính xác là **0.29**\n","        Model sử dụng mạng Lenet cho độ chỉnh xác **0.3**\n","+ Độ chính xác của hai model đều giảm mạnh khi tăng size của bức ảnh. Dự đoán là khi resize ảnh 64x64 lúc đầu nó sẽ không thể hiện đầy đủ cạnh góc của các trái cây trong hình mà đặc trưng chính chỉ là màu sắc. Thêm vào đó nữa, màu săc của các trái cây trong hình có màu sắc khác nhau. Chính vì thế, Model SVM với trích xuất vector normal sẽ tạo được độ chính xác cao với size 64x64. Vậy Model của em chưa tốt khi mà dữ liệu có màu khác nhau trong một bức ảnh nhiều và các quả có màu giống nhau.  "]},{"cell_type":"markdown","metadata":{"id":"bkqDhgeP-NnX","colab_type":"text"},"source":["#**7. Phát triển phần mềm:**\n"]},{"cell_type":"markdown","metadata":{"id":"VgM3-f1i-UNq","colab_type":"text"},"source":["(đang gặp bug)"]}]}